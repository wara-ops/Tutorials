{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7b4801",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# LLM tool calling\n",
    "\n",
    "> Disclosure: A DeepSeek-R1 LLM was involved in drafting some of the summarizing text in this tutorial. Where this was the case, it is indicated by a footnote stating the prompt. The tiny class used for queries to the LLM-as-a-service is shown in Appendix&nbsp;A. All other text and code examples were written by a human.\n",
    "\n",
    "## What is _tool calling_?<sup>1</sup>\n",
    "\n",
    "**Tool Calling in LLM Queries: A Summary**\n",
    "\n",
    "1. **Definition**: Tool calling is a technique where Large Language Models (LLMs) interpret user input as commands to invoke external tools, services, or APIs.\n",
    "\n",
    "2. **Functionality**: It enables models to execute tasks beyond their training data by interacting with databases, cloud services, custom scripts, and other systems in real-time.\n",
    "\n",
    "3. **Purpose**: Enhances the model's capabilities, allowing it to perform dynamic actions based on user requests.\n",
    "\n",
    "4. **Benefits**:\n",
    "   - Extends LLM functionality.\n",
    "   - Facilitates complex tasks through natural language input.\n",
    "\n",
    "5. **Challenges**:\n",
    "   - Potential security risks if inputs aren't properly sanitized.\n",
    "   - Requires robust error handling and API integration.\n",
    "\n",
    "This approach bridges the gap between NLP capabilities and external systems, offering versatile applications in automation, data retrieval, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee873c93",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## How is tool calling performed in practice?\n",
    "\n",
    "The process is best illustrateted with a minimal example.\n",
    "As usual, we need to connect to the LLM service and make sure to pick a model that _supports tool calling._\n",
    "To check if a model supports tool calling you can e.g. use the ollama site:\n",
    "<https://ollama.com/search?c=tools>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30a45b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!pip -q install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b270d2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "OLLAMA_HOST = 'http://10.129.20.4:9090'\n",
    "OLLAMA_MODEL = 'llama3.3:latest'\n",
    "\n",
    "client = Client(host=OLLAMA_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adbbe9",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "In addition we need to provide a _tool_, that can be as simple as the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5cf63",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add numbers\n",
    "\n",
    "    Args:\n",
    "      a (int): The first number\n",
    "      b (int): The second number\n",
    "\n",
    "    Returns:\n",
    "      int: The sum of the two numbers\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f00fd",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Here, the name of the tool is unimportant, but the type annotations and the docstring is. The LLM use python's introspection capabilities to analyze the function, but type annotation and documentation helps in getting the desired result.\n",
    "\n",
    "We can now proceed to query the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f093839",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': 'What is three plus one?'}]\n",
    "\n",
    "response = client.chat(\n",
    "    OLLAMA_MODEL,\n",
    "    messages=messages,\n",
    "    tools=[add_numbers],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0f3d0",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "The only difference to a normal query is the additional parameter `tools` which is given a list of helpers appropriate for the query.\n",
    "\n",
    "Instead of responding with an answer to the query, the LLM will repond with details of what tool to call and the arguments for the call, like follows:\n",
    "\n",
    "```python\n",
    "print(response.message.tool_calls)\n",
    "```\n",
    "```\n",
    "[ToolCall(function=Function(name='add_numbers', arguments={'a': 3, 'b': 1}))]\n",
    "```\n",
    "\n",
    "Nested in that message is a list of the name(s) of the tool(s) to call and the corresponding arguments.\n",
    "\n",
    "We then call the tool with the given arguments and feed the result back to the LLM for the final response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_of_toolcall = add_numbers(3, 1)\n",
    "\n",
    "messages.append({'role': 'tool', 'content': str(result_of_toolcall), 'name': \"add_numbers\"})\n",
    "\n",
    "final_response = client.chat(\n",
    "  OLLAMA_MODEL,\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d876fd",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Printing the final response\n",
    "```\n",
    "print(final_response.message.content)\n",
    "```\n",
    "shuold return something like (the interesting detail is the number 4):\n",
    "```\n",
    "The answer to \"three plus one\" is 4.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde505d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(final_response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f46f963",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "The only thing missing to fully automate the process is a mapping from tool names to the corresponding functions, and the simplest solution is a dictionary for look-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702754b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "available_tools = {\"add_numbers\": add_numbers}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fc838",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "With such a look-up table we can use something like the following to completely automate tool calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f1c60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def processResponse(messages, original_response, available_tools):\n",
    "    # If there was no tool call, just return the input\n",
    "    if not original_response.message.tool_calls:\n",
    "        return original_response\n",
    "    # Assume just one tool call\n",
    "    tool = original_response.message.tool_calls[0]\n",
    "    tool_name = tool.function.name\n",
    "    if tool_name not in available_tools:\n",
    "        print(f\"Unknown tool: {tool_name}\")\n",
    "        return original_response\n",
    "    fcn = available_tools[tool_name]\n",
    "    mandatory_args = tool.function.arguments\n",
    "    # Keep optional arguments (if any) separate from mandatory arguments\n",
    "    # and make sure it is a dictionary\n",
    "    optional_args = mandatory_args.pop(\"kwargs\", {})\n",
    "    if not isinstance(optional_args, dict):\n",
    "        optional_args = {}\n",
    "    # Call the tool\n",
    "    result_of_toolcall = fcn(**mandatory_args, **optional_args)\n",
    "    print(f\"Calling tool:\\n{tool_name} -> {result_of_toolcall}\")\n",
    "    # Feed the tool result to the LLM\n",
    "    messages.append(original_response.message)\n",
    "    messages.append({'role': 'tool', 'content': str(result_of_toolcall), 'name': tool_name})\n",
    "    print(\"sending result of tool call back to LLM...\")\n",
    "    # Get final response from model with function outputs\n",
    "    final_response = client.chat(\n",
    "      OLLAMA_MODEL,\n",
    "      messages=messages\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2603d8",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7393567",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': 'What is three plus one?'}]\n",
    "\n",
    "response = client.chat(\n",
    "    OLLAMA_MODEL,\n",
    "    messages=messages,\n",
    "    tools=[add_numbers],\n",
    ")\n",
    "\n",
    "response = processResponse(messages, response, available_tools)\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f10ac",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Calling REST services\n",
    "\n",
    "However, we are not limited to home grown functions to use as tools, but we can easily make use of e.g. online REST services using modules like `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a7021",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "help (requests.request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15153ca",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "As we can see from the `help` output, the request call provides enough information in its `__doc__` field (try `print(requests.request.__doc__)`) for the LLM to figure out the _schema_, i.e. the semantics of required (and optional) arguments and their types, as well as the expected return value.\n",
    "\n",
    "We'll use the freely available [meowfacts](https://github.com/wh-iterabb-it/meowfacts) service residing on <https://meowfacts.herokuapp.com/> to fetch random cat facts for the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87eca1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "messages=[{'role': 'user', 'content': \"What can https://meowfacts.herokuapp.com/ tell me about cats?\"}]\n",
    "response = client.chat(\n",
    "  OLLAMA_MODEL,\n",
    "  messages=messages,\n",
    "  tools=[requests.request],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523c061",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "```python\n",
    "print(response.message.tool_calls)\n",
    "```\n",
    "```\n",
    "[ToolCall(function=Function(name='request', arguments={'kwargs': '{\"params\": {\"id\": \"\"}}', 'method': 'GET', 'url': 'https://meowfacts.herokuapp.com/'}))]\n",
    "```\n",
    "\n",
    "There are two things to note here:\n",
    "1. the name of the tool requested by the LLM is the unqualified name `request`, not `requests.request`\n",
    "2. it got the argument to optional parameter `id` wrong, it is supposed to be numerical id of a specific fact\n",
    "\n",
    "As an exercise later, try to instruct the LLM (by modifyng the prompt) to follow the REST API [guidelines](https://github.com/wh-iterabb-it/meowfacts/tree/main?tab=readme-ov-file#example-usage).\n",
    "\n",
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce66807",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tools = {\"request\": requests.request}\n",
    "\n",
    "messages=[{'role': 'user', 'content': \"What can https://meowfacts.herokuapp.com/ tell me about cats? Respond in markdown formatted text.\"}]\n",
    "response = client.chat(\n",
    "  OLLAMA_MODEL,\n",
    "  messages=messages,\n",
    "  tools=[requests.request],\n",
    ")\n",
    "\n",
    "response = processResponse(messages, response, available_tools)\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d88822",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "As always, the answer varies from query to query, but you should get a response similar to:\n",
    "\n",
    "> MeowFacts! That\\'s a fun website. According to MeowFacts, here are some interesting and little-known facts about cats:\n",
    ">\n",
    "> 1. **Cats have scent glands on their faces**: Cats have scent glands located on either side of their nostrils, as well as on their lips, chin, and near their whiskers.\n",
    "> 2. **Cats can\\'t taste sweetness**: Unlike humans, cats lack the taste receptors for sweetness. This is because they are obligate carnivores and don\\'t need to detect sweetness in their diet.\n",
    "> 3. **A group of cats is called a \"clowder\"**: Yes, you read that right! A group of cats is officially known as a clowder.\n",
    "> 4. **Cats have three eyelids**: In addition to their upper and lower eyelids, cats also have a third eyelid called the nictitating membrane or \"haw.\" This helps keep their eyes clean and protected.\n",
    "> 5. **Cats can jump up to 5 times their own height**: Cats are known for their agility and jumping ability. They can leap impressive distances, thanks to their powerful leg muscles and flexible spines.\n",
    "> 6. **Cats purr to self-soothe**: While cats often purr when they\\'re happy or content, they also purr when they\\'re stressed, scared, or even giving birth. Purring is a way for cats to calm themselves down and regulate their breathing.\n",
    "> 7. **Cats have unique nose prints**: Just like human fingerprints, each cat\\'s nose print is unique and can be used to identify them.\n",
    "> 8. **Cats can sleep for 16 hours a day**: Cats are notorious for their love of sleep. On average, they spend around 16 hours per day snoozing, with some cats sleeping as much as 20 hours in a 24-hour period.\n",
    "> 9. **Cats can hear sounds that are too faint for humans to detect**: Cats have extremely sensitive hearing and can pick up sounds that are too quiet for humans to detect. They can also hear sounds at higher frequencies than humans can.\n",
    "> 10. **Cats can\\'t see in complete darkness**: While cats have excellent low-light vision, they can\\'t see in complete darkness. Their eyes contain a reflective layer called the tapetum lucidum, which helps them see better in low light conditions.\n",
    ">\n",
    "> These are just a few of the many fascinating facts about cats that you can find on MeowFacts. Whether you\\'re a seasoned cat owner or just a cat enthusiast, there\\'s always more to learn about these amazing animals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded57cb3",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Utilizing portal data\n",
    "\n",
    "To be written,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f4956",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "## Footnotes\n",
    "<p><small>1. Summarize the practice of 'tool calling' in an LLM query context.</small></p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4a141",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Appendix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "class LLM:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.client = Client(host='10.129.20.4:9090')\n",
    "        self.model = model\n",
    "\n",
    "    def prompt(self, query):\n",
    "        audience = \" Your audience is computer scientists, be brief but precise.\"\n",
    "        format_info = \" Use markdown format for the output.\"\n",
    "        response = self.client.chat(model=self.model, messages=[{'role': 'user', 'content': query + audience + format_info}])\n",
    "        print(response.message.content)\n",
    "        return response\n",
    "\n",
    "deepseek = LLM('deepseek-r1:70b')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
